p <- 1000
sigma <- 1
snr <- 3
beta <- snr*sigma*sqrt(log(p)/n)*c(2,-3,2,2,-3,3,-2,3,-2,3,rep(0,p-10))
X <- matrix(rnorm(n*p), nrow=n)
Y <- X%*%beta + rnorm(n,0,sigma)
x <- scale(X)
y <- Y-mean(Y)
y.norm <- sum(y^2)
system.time(pMTM(X = X, Y = Y, s0=100, prior = 'p', g=n)
)
##############################################################################
### compute sum of numbers in log scale
##  ------ARGUMENTS------
#    lx    : a vector containing values in log scale
##  ------OUTPUTS------
#    sum of numbers in lx
logSum <- function(lx) return(max(lx) + log(sum(exp(lx - max(lx)))))
##############################################################################
### score function based on correlations between predictors
##  ------ARGUMENTS------
#    a    : correlation between two predictors
#    b    : a threshold of correlations
##  ------OUTPUTS------
#    score
fnB <- function(a, b) {
vv <- exp(-9 * (1-a)/(1-b))
return(vv)
}
##############################################################################
### add score to predictors
##  ------ARGUMENTS------
#    p          : number of predictors
#    ix.vec     : a vector of indices which score need to be updated
#    wt.vector  : score vector
##  ------OUTPUTS------
#    a score vector
wtUpdate <- function(p, ix.vec, wt.vector){
score <- rep(0,p)
score[ix.vec] <- wt.vector
return(score)
}
##############################################################################
### compute the logarithm of marginal likelihood (log L(Y | gamma)) up to a normalizing constant
##  ------ARGUMENTS------
#    x           : design matrix (after normalization)
#    y           : response (after centering)
#    g           : hyperparameter used in Zellner's g-prior, default is sample size (Unit information prior)
#    gamma       : a vector of indices of predictors
#    y.norm      : l_2 norm of response
##  ------OUTPUTS------
#    logarithm of marginal likelihood up to a normalizing constant
logMl <- function(gamma, y, x, y.norm, g=nrow(x)){
gamma.abs <- length(gamma)
n <- nrow(x)
p <- ncol(x)
if (gamma.abs==0) {return (-n/2*log1p(g))
} else if (gamma.abs==1){
x.gamma <- x[,gamma]
rsq.gamma <- sum(y*x.gamma)^2/sum(x.gamma^2)/y.norm
return(-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
} else{
x.gamma <- x[,gamma]
rsq.gamma <- t(y)%*%x.gamma%*%solve(t(x.gamma)%*%x.gamma)%*%t(x.gamma)%*%y/y.norm
return(-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
}
}
##############################################################################
### compute the difference of logarithm of prior during MH step for add/remove move
##  ------ARGUMENTS------
#    prior       : if 'p': model prior is (1/p)^modelsize; else: Beta-Binomial prior
#    move.type   : -1: remove a predictor; 1: add a predictor
#    p           : number of predictors
#    gamma.abs   : current model size
#    alpha       : hyperparameter of Beta-Binomial prior, default is 10
#    beta        : hyperparameter of Beta-Binomial prior, default is p-10
##  ------OUTPUTS------
#    the difference of logarithm of prior using in the MH updating
logPrior <- function(prior, move.type, p, gamma.abs=0, alpha=10, beta=p-10){
if (prior=='p'){
return(-move.type*log(p))
} else {
if (move.type==1){
return(log(gamma.abs+alpha)-log(p-gamma.abs-1+beta))
}
else {
return(-log(gamma.abs+alpha-1)+log(p-gamma.abs+beta))
}
}
}
##############################################################################
### used especially for reproducing the example
### compute the logarithm of posterior probability of a given model (p(gamma | Y)) up to a normalizing constant
##  ------ARGUMENTS------
#    prior       : 'p': model prior is (1/p)^kappa*modelsize; 'uni': Uniform prior; else: Beta-Binomial prior
#    x           : design matrix (after normalization)
#    y           : response (after centering)
#    y.norm      : l_2 norm of response
#    gamma       : a vector of indices of predictors
#    g           : hyperparameter used in Zellner's g-prior, default is sample size (Unit information prior)
#    kappa       : hyperparameter used in sparisty prior, default is 3 (for reproducing)
#    alpha       : hyperparameter of Beta-Binomial prior, default is 10
#    beta        : hyperparameter of Beta-Binomial prior, default is p-10
##  ------OUTPUTS------
#    the logarithm of posterior probability up to a normalizing constant
logPostc <- function(gamma, y, x, y.norm, prior, g=nrow(x), kappa=3, alpha=10, beta=ncol(x)-10){
gamma.abs <- length(gamma)
n <- nrow(x)
p <- ncol(x)
if (prior=='p'){
if (gamma.abs==0) {return (-n/2*log1p(g))
} else if (gamma.abs==1){
x.gamma <- x[,gamma]
rsq.gamma <- sum(y*x.gamma)^2/sum(x.gamma^2)/y.norm
return(-kappa*gamma.abs*log(p)-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
} else{
x.gamma <- x[,gamma]
rsq.gamma <- t(y)%*%x.gamma%*%solve(t(x.gamma)%*%x.gamma)%*%t(x.gamma)%*%y/y.norm
return(-kappa*gamma.abs*log(p)-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
}
} else if (prior=='uni') {
if (gamma.abs==0) {return (-n/2*log1p(g))
} else if (gamma.abs==1){
x.gamma <- x[,gamma]
rsq.gamma <- sum(y*x.gamma)^2/sum(x.gamma^2)/y.norm
return(-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
} else{
x.gamma <- x[,gamma]
rsq.gamma <- t(y)%*%x.gamma%*%solve(t(x.gamma)%*%x.gamma)%*%t(x.gamma)%*%y/y.norm
return(-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
}
} else {
if (gamma.abs==0) {return (log(beta(alpha,beta+p))-n/2*log1p(g))
} else if (gamma.abs==1){
x.gamma <- x[,gamma]
rsq.gamma <- sum(y*x.gamma)^2/sum(x.gamma^2)/y.norm
return(log(beta(alpha+1,beta+p-1))-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
} else{
x.gamma <- x[,gamma]
rsq.gamma <- t(y)%*%x.gamma%*%solve(t(x.gamma)%*%x.gamma)%*%t(x.gamma)%*%y/y.norm
return(log(beta(alpha+gamma.abs,beta+p-gamma.abs))-gamma.abs/2*log1p(g)-n/2*log1p(g*(1-rsq.gamma)))
}
}
}
##############################################################################
### convert gamma from indices form to 0/1 form
### e.g. input: gamma <- c(1,3,5,7), p <- 8 =>  output: c(1,0,1,0,1,0,1,0)
##  ------ARGUMENTS------
#    gamma  : a vector containing indices of predictors
#    p      : number of predictors
##  ------OUTPUTS------
#    incl   : a vector of indicators of indices
inclusion <- function(gamma, p) {
incl <- rep(0,p)
incl[gamma] <- 1
return(incl)
}
##############################################################################
### split and convert gamma from character to 0/1 numerical values
##  ------ARGUMENTS------
#    gamma.sort      : a vector of appearance times with model as vector name
##  ------OUTPUTS------
#    an indicator vector
gammaSplit <- function(gamma.sort) {return(which(as.numeric(strsplit(gamma.sort, " ")[[1]])==1))}
##############################################################################
### compute the beta given a single model
##  ------ARGUMENTS------
#    x           : design matrix (after normalization)
#    Y           : response
#    sdx         : a vector containing standard deviations of each predictor
#    g           : hyperparameter used in Zellner's g-prior
#    gamma       : a vector of indices of predictors
##  ------OUTPUTS------
#    beta corresponding to the given model
modelCoef <- function(gamma, g, x, Y, sdx){
gamma.abs <- length(gamma)
p <- ncol(x)
coef <- rep(0,p)
if (gamma.abs==0) {return(coef)} else if (gamma.abs==1){
coef[gamma] <- g/(g+1)*sum(x[,gamma]*Y)/sum(x[,gamma]^2)/sdx[gamma]
return(coef)
} else {
coef[gamma] <- g/(g+1)*solve(t(x[,gamma])%*%x[,gamma])%*%t(x[,gamma])%*%Y/sdx[gamma]
return(coef)
}
}
##############################################################################
### compute the beta using Bayesian model averaging
##  ------ARGUMENTS------
#    x           : design matrix (after normalization)
#    Y           : response
#    sdx         : a vector containing standard deviations of each predictor
#    g           : hyperparameter used in Zellner's g-prior
#    gamma.model : a list, every element is a vector of indices of predictors
#    post.prob   : posterior probabilities of models in gamma.model
##  ------OUTPUTS------
#    the beta using Bayesian model averaging
bmaCoef <- function(x, Y, sdx, g, gamma.model, post.prob){
coef <- t(sapply(gamma.model, modelCoef, g=g, x=x, Y=Y, sdx=sdx))
return(apply(coef*post.prob,2,sum))
}
##############################################################################
### compute RSS of given design matrix, response and beta
##  ------ARGUMENTS------
#    beta      : a coefficient vector
#    x         : design matrix (after normalization)
#    y         : response (after centering)
##  ------OUTPUTS------
#    RSS
score <- function(beta,x,y){
return(sum((y-x%*%beta)^2))
}
##############################################################################
### get the best beta from EMVS output in terms of RSS (equivalent to BIC)
### from the betas corresponding to highest probability model
##  ------ARGUMENTS------
#    emvs.fit  : a list containing the result returned from EMVS()
#    x         : design matrix (after normalization)
#    y         : response (after centering)
##  ------OUTPUTS------
#    the beta achieves minimal RSS
emvsBest <- function(emvs.fit,x,y){
log.post <- emvs.fit$log_g_function
max.ix <- which(log.post==max(log.post))
if (length(max.ix)==1){
return(emvs.fit$betas[max.ix,])
} else {
best.ix <- which.min(apply(emvs.fit$betas[max.ix,], 1, score, x=x, y=y))
return(emvs.fit$betas[max.ix[best.ix],])
}
}
system.time(pMTM(X = X, Y = Y, s0=100, prior = 'p', g=n))
pMTM <- function(X, Y, s0, g=nrow(X), M = 5, n.iter = 1e4, burnin = 2000, prior){
n <- nrow(X)
p <- ncol(X)
x <- scale(X)
y <- Y - mean(Y)
y.norm <- sum(y^2)
gamma <- integer(0)
n.acpt <- rep(0,3)
n.prop <- rep(0,3)
impt.prob <- min(1,M/p)
gamma.abs <- length(gamma)
move.prob <- matrix(1/3, s0, 3)
move.prob[1,] <- c(1,0,0)
move.prob[s0,] <- c(0,1,0)
model.size <- rep(NA,n.iter)
gamma.store <- vector('list', n.iter)
for (iter in 1:n.iter){
move.type <-  sample(3,1,prob=move.prob[gamma.abs+1,])
n.prop[move.type] <- n.prop[move.type] + 1
weight <- rep(impt.prob,p)
if (move.type==1){ ## add
weight[gamma] <- 0
eta <-   which(as.logical(rbinom(p,1,weight)))
n.fwd <- length(eta)
if (n.fwd>0){
gamma.tilde <- mclapply(eta, function(j) return(c(gamma, j)), mc.cores = 4, mc.preschedule=F)
fwd.nbhd.ls <- simplify2array(mclapply(gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(n.fwd, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
fwd.prob <- move.prob[gamma.abs+1,1] * impt.prob
if (gamma.abs > 0){
bwd.gamma.tilde <- mclapply(1:(gamma.abs+1), function(j) return(gamma.prime[-j]), mc.cores = 4, mc.preschedule=F)
bwd.nbhd.ls <- simplify2array(mclapply(bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
bwd.lp <- logSum(bwd.nbhd.ls)
} else {
bwd.lp <- logMl(gamma=gamma, y=y, x=x, y.norm=y.norm, g=g)
}
bwd.prob <- move.prob[gamma.abs+2,2]
acpt.rate <- fwd.lp - bwd.lp + log(bwd.prob) - log(fwd.prob) + logPrior(prior=prior, move.type=1, p=p, gamma.abs=gamma.abs)
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[1] <- n.acpt[1] + 1
gamma.abs <- gamma.abs + 1
}
}
} else if (move.type==2){ ## remove
gamma.tilde <- mclapply(1:gamma.abs, function(j) return(gamma[-j]), mc.cores = 4, mc.preschedule=F)
fwd.nbhd.ls <- simplify2array(mclapply(gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(gamma.abs, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
fwd.prob <- move.prob[gamma.abs+1,2]
bwd.prob <- move.prob[gamma.abs,1] * impt.prob
weight[gamma.prime] <- 0
weight[gamma[fwd.ix]] <- 1
eta <- which(as.logical(rbinom(p,1,weight)))
n.bwd <- length(eta)
bwd.gamma.tilde <- mclapply(eta, function(j) return(c(gamma.prime, j)), mc.cores = 4, mc.preschedule=F)
bwd.nbhd.ls <- simplify2array(mclapply(bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
bwd.lp <- logSum(bwd.nbhd.ls)
acpt.rate <- fwd.lp - bwd.lp + log(bwd.prob) - log(fwd.prob) + logPrior(prior=prior, move.type=-1, p=p, gamma.abs=gamma.abs)
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[2] <- n.acpt[2] + 1
gamma.abs <- gamma.abs - 1
}
} else { ## swap
weight <- rep(min(1, M/p/gamma.abs), p)
weight[gamma] <- 0
fwd.var.add <- integer(0)
fwd.ix.rem <- integer(0)
n.fwd <- 0
for(ix in 1:gamma.abs){
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.fwd.temp <- length(eta.add)
fwd.var.add <- c(fwd.var.add, eta.add)
fwd.ix.rem <- c(fwd.ix.rem, rep(ix, n.fwd.temp))
n.fwd <- n.fwd + n.fwd.temp
}
if(n.fwd > 0){
gamma.tilde <- mclapply(1:n.fwd, function(j) return(c(gamma[-fwd.ix.rem[j]], fwd.var.add[j])), mc.cores = 4, mc.preschedule=F)
fwd.nbhd.ls <- simplify2array(mclapply(gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(n.fwd, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
var.add <- fwd.var.add[fwd.ix]
var.rem <- gamma[fwd.ix.rem[fwd.ix]]
weight[var.add] <- 0
weight[var.rem] <- min(1, M/p/gamma.abs)
bwd.var.add <- integer(0)
bwd.ix.rem <- integer(0)
n.bwd <- 0
if (gamma.abs > 1){
for(ix in 1:(gamma.abs-1)){
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.bwd.temp <- length(eta.add)
bwd.var.add <- c(bwd.var.add, eta.add)
bwd.ix.rem <- c(bwd.ix.rem, rep(ix, n.bwd.temp))
n.bwd <- n.bwd + n.bwd.temp
}
}
weight[var.rem] <- 1
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.bwd.temp <- length(eta.add)
bwd.var.add <- c(bwd.var.add, eta.add)
bwd.ix.rem <- c(bwd.ix.rem, rep(gamma.abs, n.bwd.temp))
n.bwd <- n.bwd + n.bwd.temp
bwd.gamma.tilde <- mclapply(1:n.bwd, function(j) return(c(gamma.prime[-bwd.ix.rem[j]], bwd.var.add[j])), mc.cores = 4, mc.preschedule=F)
bwd.nbhd.ls <- simplify2array(mclapply(bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g, mc.cores = 4, mc.preschedule=F))
bwd.lp <- logSum(bwd.nbhd.ls)
acpt.rate <- fwd.lp - bwd.lp
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[3] <- n.acpt[3] + 1
}
}
}
gamma.store[[iter]] <- gamma
model.size[iter] <- length(gamma)
}
gamma.mat <- t(simplify2array(mclapply(gamma.store[-(1:burnin)],inclusion, p=p, mc.cores = 4, mc.preschedule=F)))
incl.prob <- apply(gamma.mat,2,sum)/(n.iter-burnin)
MPM <- which(incl.prob>=0.5)
gamma.count <- table(apply(gamma.mat, 1, paste, collapse=" "))
gamma.sort <- sort(gamma.count,decreasing = T)
post.prob <- as.numeric(gamma.sort)/(n.iter-burnin)
gamma.model <- mclapply(names(gamma.sort),gammaSplit, mc.cores = 4, mc.preschedule=F)
HPM <- gamma.model[[1]]
model.size.avg <- mean(model.size[-(1:burnin)])
model.size.HPM <- length(MPM)
model.size.MPM <- length(HPM)
return(list(gamma.model=gamma.model, post.prob=post.prob, n.prop=n.prop, n.acpt=n.acpt, n.iter=n.iter, MPM=MPM, HPM=HPM, burnin=burnin, model.size.avg=model.size.avg,model.size.MPM=model.size.MPM,model.size.HPM=model.size.HPM))
}
system.time(pMTM(X = X, Y = Y, s0=100, prior = 'p', g=n))
library(parallel)
system.time(pMTM(X = X, Y = Y, s0=100, prior = 'p', g=n))
?sink
library(parallel)
cl <- makeForkCluster(4)
pMTM <- function(X, Y, s0, g=nrow(X), M = 5, n.iter = 1e4, burnin = 2000, prior){
n <- nrow(X)
p <- ncol(X)
x <- scale(X)
y <- Y - mean(Y)
y.norm <- sum(y^2)
gamma <- integer(0)
n.acpt <- rep(0,3)
n.prop <- rep(0,3)
impt.prob <- min(1,M/p)
gamma.abs <- length(gamma)
move.prob <- matrix(1/3, s0, 3)
move.prob[1,] <- c(1,0,0)
move.prob[s0,] <- c(0,1,0)
model.size <- rep(NA,n.iter)
gamma.store <- vector('list', n.iter)
for (iter in 1:n.iter){
move.type <-  sample(3,1,prob=move.prob[gamma.abs+1,])
n.prop[move.type] <- n.prop[move.type] + 1
weight <- rep(impt.prob,p)
if (move.type==1){ ## add
weight[gamma] <- 0
eta <-   which(as.logical(rbinom(p,1,weight)))
n.fwd <- length(eta)
if (n.fwd>0){
gamma.tilde <- parLapply(cl, eta, function(j) return(c(gamma, j)))
fwd.nbhd.ls <- parSapply(cl, gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(n.fwd, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
fwd.prob <- move.prob[gamma.abs+1,1] * impt.prob
if (gamma.abs > 0){
bwd.gamma.tilde <- parLapply(cl, 1:(gamma.abs+1), function(j) return(gamma.prime[-j]))
bwd.nbhd.ls <- parSapply(cl, bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
bwd.lp <- logSum(bwd.nbhd.ls)
} else {
bwd.lp <- logMl(gamma=gamma, y=y, x=x, y.norm=y.norm, g=g)
}
bwd.prob <- move.prob[gamma.abs+2,2]
acpt.rate <- fwd.lp - bwd.lp + log(bwd.prob) - log(fwd.prob) + logPrior(prior=prior, move.type=1, p=p, gamma.abs=gamma.abs)
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[1] <- n.acpt[1] + 1
gamma.abs <- gamma.abs + 1
}
}
} else if (move.type==2){ ## remove
gamma.tilde <- parLapply(cl, 1:gamma.abs, function(j) return(gamma[-j]))
fwd.nbhd.ls <- parSapply(cl, gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(gamma.abs, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
fwd.prob <- move.prob[gamma.abs+1,2]
bwd.prob <- move.prob[gamma.abs,1] * impt.prob
weight[gamma.prime] <- 0
weight[gamma[fwd.ix]] <- 1
eta <- which(as.logical(rbinom(p,1,weight)))
n.bwd <- length(eta)
bwd.gamma.tilde <- parLapply(cl, eta, function(j) return(c(gamma.prime, j)))
bwd.nbhd.ls <- parSapply(cl, bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
bwd.lp <- logSum(bwd.nbhd.ls)
acpt.rate <- fwd.lp - bwd.lp + log(bwd.prob) - log(fwd.prob) + logPrior(prior=prior, move.type=-1, p=p, gamma.abs=gamma.abs)
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[2] <- n.acpt[2] + 1
gamma.abs <- gamma.abs - 1
}
} else { ## swap
weight <- rep(min(1, M/p/gamma.abs), p)
weight[gamma] <- 0
fwd.var.add <- integer(0)
fwd.ix.rem <- integer(0)
n.fwd <- 0
for(ix in 1:gamma.abs){
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.fwd.temp <- length(eta.add)
fwd.var.add <- c(fwd.var.add, eta.add)
fwd.ix.rem <- c(fwd.ix.rem, rep(ix, n.fwd.temp))
n.fwd <- n.fwd + n.fwd.temp
}
if(n.fwd > 0){
gamma.tilde <- parLapply(cl, 1:n.fwd, function(j) return(c(gamma[-fwd.ix.rem[j]], fwd.var.add[j])))
fwd.nbhd.ls <- parSapply(cl, gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
fwd.lp <- logSum(fwd.nbhd.ls)
fwd.ix <- sample(n.fwd, 1, prob = exp(fwd.nbhd.ls - fwd.lp))
gamma.prime <- gamma.tilde[[fwd.ix]]
var.add <- fwd.var.add[fwd.ix]
var.rem <- gamma[fwd.ix.rem[fwd.ix]]
weight[var.add] <- 0
weight[var.rem] <- min(1, M/p/gamma.abs)
bwd.var.add <- integer(0)
bwd.ix.rem <- integer(0)
n.bwd <- 0
if (gamma.abs > 1){
for(ix in 1:(gamma.abs-1)){
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.bwd.temp <- length(eta.add)
bwd.var.add <- c(bwd.var.add, eta.add)
bwd.ix.rem <- c(bwd.ix.rem, rep(ix, n.bwd.temp))
n.bwd <- n.bwd + n.bwd.temp
}
}
weight[var.rem] <- 1
eta.add <- which(as.logical(rbinom(p,1,weight)))
n.bwd.temp <- length(eta.add)
bwd.var.add <- c(bwd.var.add, eta.add)
bwd.ix.rem <- c(bwd.ix.rem, rep(gamma.abs, n.bwd.temp))
n.bwd <- n.bwd + n.bwd.temp
bwd.gamma.tilde <- parLapply(cl, 1:n.bwd, function(j) return(c(gamma.prime[-bwd.ix.rem[j]], bwd.var.add[j])))
bwd.nbhd.ls <- parSapply(cl, bwd.gamma.tilde, logMl, y=y, x=x, y.norm=y.norm, g=g)
bwd.lp <- logSum(bwd.nbhd.ls)
acpt.rate <- fwd.lp - bwd.lp
if (log(runif(1))<acpt.rate) {
gamma <- sort(gamma.prime)
n.acpt[3] <- n.acpt[3] + 1
}
}
}
gamma.store[[iter]] <- gamma
model.size[iter] <- length(gamma)
}
gamma.mat <- t(parSapply(cl, gamma.store[-(1:burnin)],inclusion, p=p))
incl.prob <- apply(gamma.mat,2,sum)/(n.iter-burnin)
MPM <- which(incl.prob>=0.5)
gamma.count <- table(apply(gamma.mat, 1, paste, collapse=" "))
gamma.sort <- sort(gamma.count,decreasing = T)
post.prob <- as.numeric(gamma.sort)/(n.iter-burnin)
gamma.model <- parLapply(cl, names(gamma.sort),gammaSplit)
HPM <- gamma.model[[1]]
model.size.avg <- mean(model.size[-(1:burnin)])
model.size.HPM <- length(MPM)
model.size.MPM <- length(HPM)
return(list(gamma.model=gamma.model, post.prob=post.prob, n.prop=n.prop, n.acpt=n.acpt, n.iter=n.iter, MPM=MPM, HPM=HPM, burnin=burnin, model.size.avg=model.size.avg,model.size.MPM=model.size.MPM,model.size.HPM=model.size.HPM))
}
system.time(pMTM(X = X, Y = Y, s0=100, prior = 'p', g=n))
?parLapply
?system.time
stopCluster()
stopCluster(cl)
cl
